	Built a 3-wheeled autonomous Raspberry Pi 4 robot controlled by ChatGPT that can ‘listen’ to speech, ‘speak’ or do command movements as a response, and avoid collision by ‘seeing’. 
  Connected the hardware inputs to the chatbot in Python, optimised the script to reduce latency, and devised and implemented the idea of regular image capture to ‘see’. 
	The robot produced a response latency 10 – 50 seconds depending on the complexity of the user input.

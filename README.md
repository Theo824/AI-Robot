	Built a 3-wheeled autonomous Raspberry Pi 4 robot controlled by ChatGPT that can 
    ‘listen’ to speech, 
    ‘speak’ or do command movements as a response, 
    and avoid collision by ‘seeing’. 
    
    Connected the hardware inputs to the chatbot in Python, 
    optimised the script to reduce latency, 
    and devised and implemented the idea of regular image capture to ‘see’. 
    
    The robot produced a response latency 10 – 50 seconds depending on the complexity of the user input.

    I had to compress the video demonstration to keep it under GitHub’s maximum size limit, 
	which explains the reduced quality.

For more information on the process of making this project, please look at solarCharger24-25_Logbook.pdf.

https://github.com/user-attachments/assets/ee055535-6858-4edb-8f1f-de28745f9a98

![robotpic](https://github.com/user-attachments/assets/d8fbabf0-e7f7-4ba0-8f97-9264a097577a)
